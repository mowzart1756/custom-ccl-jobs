{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Worksheet named 'DATA' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\whittlj2\\Github-Repo\\custom-ccl-jobs\\CUSTOM JOBS\\Pathology Order Estimator from Results\\Subgroup count.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 124>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/whittlj2/Github-Repo/custom-ccl-jobs/CUSTOM%20JOBS/Pathology%20Order%20Estimator%20from%20Results/Subgroup%20count.ipynb#W0sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/whittlj2/Github-Repo/custom-ccl-jobs/CUSTOM%20JOBS/Pathology%20Order%20Estimator%20from%20Results/Subgroup%20count.ipynb#W0sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39m#read_file = pd.read_csv (target_location, engine = 'python', dtype = 'str', delimiter= '|')\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/whittlj2/Github-Repo/custom-ccl-jobs/CUSTOM%20JOBS/Pathology%20Order%20Estimator%20from%20Results/Subgroup%20count.ipynb#W0sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m dataframe_1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(target_location, dtype \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mstr\u001b[39;49m\u001b[39m'\u001b[39;49m, sheet_name\u001b[39m=\u001b[39;49m s_n)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/whittlj2/Github-Repo/custom-ccl-jobs/CUSTOM%20JOBS/Pathology%20Order%20Estimator%20from%20Results/Subgroup%20count.ipynb#W0sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m \u001b[39m# Count Total Results\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/whittlj2/Github-Repo/custom-ccl-jobs/CUSTOM%20JOBS/Pathology%20Order%20Estimator%20from%20Results/Subgroup%20count.ipynb#W0sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m raw_data_rows \u001b[39m=\u001b[39m dataframe_1\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\whittlj2\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\whittlj2\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:465\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    460\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m     )\n\u001b[0;32m    464\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 465\u001b[0m     data \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mparse(\n\u001b[0;32m    466\u001b[0m         sheet_name\u001b[39m=\u001b[39;49msheet_name,\n\u001b[0;32m    467\u001b[0m         header\u001b[39m=\u001b[39;49mheader,\n\u001b[0;32m    468\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    469\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m    470\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[0;32m    471\u001b[0m         squeeze\u001b[39m=\u001b[39;49msqueeze,\n\u001b[0;32m    472\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    473\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[0;32m    474\u001b[0m         true_values\u001b[39m=\u001b[39;49mtrue_values,\n\u001b[0;32m    475\u001b[0m         false_values\u001b[39m=\u001b[39;49mfalse_values,\n\u001b[0;32m    476\u001b[0m         skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[0;32m    477\u001b[0m         nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[0;32m    478\u001b[0m         na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[0;32m    479\u001b[0m         keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[0;32m    480\u001b[0m         na_filter\u001b[39m=\u001b[39;49mna_filter,\n\u001b[0;32m    481\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    482\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m    483\u001b[0m         date_parser\u001b[39m=\u001b[39;49mdate_parser,\n\u001b[0;32m    484\u001b[0m         thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[0;32m    485\u001b[0m         decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[0;32m    486\u001b[0m         comment\u001b[39m=\u001b[39;49mcomment,\n\u001b[0;32m    487\u001b[0m         skipfooter\u001b[39m=\u001b[39;49mskipfooter,\n\u001b[0;32m    488\u001b[0m         convert_float\u001b[39m=\u001b[39;49mconvert_float,\n\u001b[0;32m    489\u001b[0m         mangle_dupe_cols\u001b[39m=\u001b[39;49mmangle_dupe_cols,\n\u001b[0;32m    490\u001b[0m     )\n\u001b[0;32m    491\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     \u001b[39m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    493\u001b[0m     \u001b[39mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32mc:\\Users\\whittlj2\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1458\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m   1424\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\n\u001b[0;32m   1425\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1426\u001b[0m     sheet_name: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m   1446\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, DataFrame] \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1447\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m \u001b[39m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[39m        DataFrame from the passed in Excel file.\u001b[39;00m\n\u001b[0;32m   1457\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mparse(\n\u001b[0;32m   1459\u001b[0m         sheet_name\u001b[39m=\u001b[39msheet_name,\n\u001b[0;32m   1460\u001b[0m         header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   1461\u001b[0m         names\u001b[39m=\u001b[39mnames,\n\u001b[0;32m   1462\u001b[0m         index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[0;32m   1463\u001b[0m         usecols\u001b[39m=\u001b[39musecols,\n\u001b[0;32m   1464\u001b[0m         squeeze\u001b[39m=\u001b[39msqueeze,\n\u001b[0;32m   1465\u001b[0m         converters\u001b[39m=\u001b[39mconverters,\n\u001b[0;32m   1466\u001b[0m         true_values\u001b[39m=\u001b[39mtrue_values,\n\u001b[0;32m   1467\u001b[0m         false_values\u001b[39m=\u001b[39mfalse_values,\n\u001b[0;32m   1468\u001b[0m         skiprows\u001b[39m=\u001b[39mskiprows,\n\u001b[0;32m   1469\u001b[0m         nrows\u001b[39m=\u001b[39mnrows,\n\u001b[0;32m   1470\u001b[0m         na_values\u001b[39m=\u001b[39mna_values,\n\u001b[0;32m   1471\u001b[0m         parse_dates\u001b[39m=\u001b[39mparse_dates,\n\u001b[0;32m   1472\u001b[0m         date_parser\u001b[39m=\u001b[39mdate_parser,\n\u001b[0;32m   1473\u001b[0m         thousands\u001b[39m=\u001b[39mthousands,\n\u001b[0;32m   1474\u001b[0m         comment\u001b[39m=\u001b[39mcomment,\n\u001b[0;32m   1475\u001b[0m         skipfooter\u001b[39m=\u001b[39mskipfooter,\n\u001b[0;32m   1476\u001b[0m         convert_float\u001b[39m=\u001b[39mconvert_float,\n\u001b[0;32m   1477\u001b[0m         mangle_dupe_cols\u001b[39m=\u001b[39mmangle_dupe_cols,\n\u001b[0;32m   1478\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m   1479\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\whittlj2\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:634\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReading sheet \u001b[39m\u001b[39m{\u001b[39;00masheetname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(asheetname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     sheet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_sheet_by_name(asheetname)\n\u001b[0;32m    635\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# assume an integer if not a string\u001b[39;00m\n\u001b[0;32m    636\u001b[0m     sheet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_sheet_by_index(asheetname)\n",
      "File \u001b[1;32mc:\\Users\\whittlj2\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:545\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_sheet_by_name\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 545\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraise_if_bad_sheet_by_name(name)\n\u001b[0;32m    546\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbook[name]\n",
      "File \u001b[1;32mc:\\Users\\whittlj2\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:570\u001b[0m, in \u001b[0;36mBaseExcelReader.raise_if_bad_sheet_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_if_bad_sheet_by_name\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    569\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msheet_names:\n\u001b[1;32m--> 570\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWorksheet named \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Worksheet named 'DATA' not found"
     ]
    }
   ],
   "source": [
    "#location of excel file\n",
    "target_location = r'C:\\\\Jan_2022_Path_Data.xlsx'\n",
    "#name of the sheet\n",
    "s_n = \"DATA\"\n",
    "output_location = r'C:\\\\Jan_2022_Path_Data_Out.xlsx'\n",
    "\n",
    "# This is how the results are grouped (using event codes of results)\n",
    "dictionary_1 = {\n",
    "\"Total of FBE\": [\"4054683\"]\t\t\t\t\t\t\t\n",
    ",\n",
    "\"Total of UEC\":\n",
    "    [\n",
    "    \"4053577\"\n",
    "    ,\"4053428\"\n",
    "    ,\"4052753\"\n",
    "    ,\"4052629\"\n",
    "    ,\"4054350\"\n",
    "    ,\"97136118\"\n",
    "    ,\"2700655\"\n",
    "    ]\n",
    ",\n",
    "\"Total of LFT\":\n",
    "    [\n",
    "    \"4052635\"   \n",
    "    ,\"4052500\"  \n",
    "    ,\"4052612\"  \n",
    "    ,\"4052496\"  \n",
    "    ,\"4053255\"  \n",
    "    ,\"4053736\"  \n",
    "    ,\"4052489\"  \n",
    "    ,\"4053257\"  \n",
    "    ]\n",
    ",\n",
    "\"Total of CMP\":\n",
    "    [\n",
    "    \"4052668\"\n",
    "    ,\"4052683\"\n",
    "    ,\"4053675\"\n",
    "    ,\"4053554\"\n",
    "    ]\n",
    ",\t\t\n",
    "\"Total of Blood Gas\":[\"11340886\"]\n",
    ",\n",
    "\"Total of Coagultion Studies\":[\"9641993\"]\n",
    ",\n",
    "\"Total of Thyroid Function Tests (TFT)\":[\"12781681\"]\n",
    ",\n",
    "\"Total of Iron Studies\":[\"9641618\"]\n",
    ",\n",
    "\"Total of HBA1C\": [\"11340917\"]\n",
    ",\t\t\t\t\t\t\t\n",
    "\"Total of Vitamin D\":[\"12781698\"]\n",
    ",\n",
    "\"Glucose Tolerance Test\": [\"4053286\"]\n",
    ",\n",
    "\"Blood Group and Antibody Screen\": [\"4057925\"]\n",
    ",\n",
    "\"Iron Studies - Iron, Ferritin and Transferrin\":\n",
    "    [\n",
    "    \"4053411\"\n",
    "    , \"4053099\"\n",
    "    , \"4053987\"\n",
    "    ]\n",
    ",\n",
    "\"Hb A1c/Hb Total Ratio mmol/mol\": [\"89139532\"]\n",
    ",\n",
    "\"Glucose Tolerance Test GTT\": [\"4053286\"]\n",
    "}\n",
    "\n",
    "dictionary_2 = {\n",
    "    \"Routine Biochemistry\":\n",
    "        [\n",
    "            \"4053577\"\n",
    "            ,\"4053428\"\n",
    "            ,\"4052753\"\n",
    "            ,\"4052629\"\n",
    "            ,\"4054350\"\n",
    "            ,\"2700655\"\n",
    "            ,\"4052469\"\n",
    "            ,\"4052500\"\n",
    "            ,\"4052612\"\n",
    "            ,\"4052635\"\n",
    "            ,\"4053255\"\n",
    "            ,\"4053736\"\n",
    "            ,\"4052489\"\n",
    "            ,\"4052668\"\n",
    "            ,\"4053554\"\n",
    "            ,\"4053675\"\n",
    "            ,\"4054349\"\n",
    "            ,\"10333933\"\n",
    "            ,\"4053465\"\n",
    "            ,\"4055520\"\n",
    "        ]\n",
    "    ,\n",
    "    \"Hormones\" : \n",
    "        [\n",
    "            \"4053478\"\n",
    "            ,\"4053215\"\n",
    "            ,\"4053036\"\n",
    "            ,\"4053900\"\n",
    "            ,\"4053843\"\n",
    "            ,\"4053743\"\n",
    "        ]\n",
    "    ,\n",
    "    \"Tumour Markers\" :\n",
    "        [\n",
    "            \"127824840\"\n",
    "            ,\"12781700\"\n",
    "            ,\"83526478\"\n",
    "            ,\"83526473\"\n",
    "        ]\n",
    "    ,\n",
    "    \"Coagulation\":\n",
    "        [\n",
    "            \"9375447\"\n",
    "            ,\"40544796\"\n",
    "            ,\"4054684\"\n",
    "        ]   \n",
    "}\n",
    "\n",
    "#READ\n",
    "import pandas as pd\n",
    "#read_file = pd.read_csv (target_location, engine = 'python', dtype = 'str', delimiter= '|')\n",
    "dataframe_1 = pd.read_excel(target_location, dtype = 'str', sheet_name= s_n)\n",
    "\n",
    "# Count Total Results\n",
    "raw_data_rows = dataframe_1.shape[0]\n",
    "\n",
    "# List of Event codes that are in the dictionary_1\n",
    "concatenated_list = []\n",
    "# Iterate over the dictionary values and use the extend method to concatenate the lists\n",
    "for values in dictionary_1.values():\n",
    "    concatenated_list.extend(values)\n",
    "dataframe_2 = dataframe_1[dataframe_1['EVENT_CODE'].isin(concatenated_list)]\n",
    "analysed_data_rows_1 = dataframe_2.shape[0]\n",
    "\n",
    "concatenated_list_2 = []\n",
    "# Iterate over the dictionary values and use the extend method to concatenate the lists\n",
    "for values in dictionary_2.values():\n",
    "    concatenated_list_2.extend(values)\n",
    "dataframe_3 = dataframe_1[dataframe_1['EVENT_CODE'].isin(concatenated_list_2)]\n",
    "analysed_data_rows_2 = dataframe_3.shape[0]\n",
    "\n",
    "print('Number of results in original file: ', raw_data_rows)\n",
    "print('Number of results that are codes looked at in pass 1: ', analysed_data_rows_1)\n",
    "print('Number of results that are codes looked at in pass 2: ', analysed_data_rows_2)\n",
    "\n",
    "\n",
    "dictionary_counts = {\"ITEM\":\"COUNT\"}\n",
    "\n",
    "# Loop through each type of tests in dictionary_1 and count the results for that test.\n",
    "for key, value in dictionary_1.items():\n",
    "    # Create a dataframe filtered with only tests for the orders in the key\n",
    "    temp_tests_df = dataframe_1[dataframe_1['EVENT_CODE'].isin(value)]\n",
    "\n",
    "    #variable for counting\n",
    "    temp_count_order = int(0)\n",
    "    \n",
    "    # Get a list of all unique test samples patient id and datetime keys\n",
    "    unique_test_batches = temp_tests_df['PATIENT_ID_AND_DT'].unique()\n",
    "    \n",
    "    for a_batch_key in unique_test_batches:\n",
    "        #create a temporary dataframe of all the results with just that combination of datetime and patientid\n",
    "        df_temp_filtered = temp_tests_df[temp_tests_df['PATIENT_ID_AND_DT'] == a_batch_key]\n",
    "        # Check if all elements are in the list\n",
    "        TF_bool = all(elem in df_temp_filtered['EVENT_CODE'].values for elem in value)\n",
    "        if TF_bool == True:\n",
    "            temp_count_order += 1\n",
    "    dictionary_counts[key] = temp_count_order\n",
    "\n",
    "# Loop through each type of test in dictionary 2 and count the results for that test using if conditions\n",
    "for key, value in dictionary_2.items():\n",
    "    # Create a dataframe filtered with only tests for the orders in the key eg datafram with only Hormones\n",
    "    temp_tests_df = dataframe_1[dataframe_1['EVENT_CODE'].isin(value)]\n",
    "\n",
    "    #variable for counting a tests of the given key\n",
    "    temp_count_order = int(0)\n",
    "    \n",
    "    # Get a list of all unique patientid/datetime keys for the given key eg for Hormones\n",
    "    unique_test_batches = temp_tests_df['PATIENT_ID_AND_DT'].unique()\n",
    "    \n",
    "\n",
    "    # Get overall counts for each key eg count for \"Tumour Markers\"\n",
    "    for a_batch_key in unique_test_batches:\n",
    "        #create a temporary dataframe of all the results with just that combination of datetime and patientid\n",
    "        df_temp_filtered = temp_tests_df[temp_tests_df['PATIENT_ID_AND_DT'] == a_batch_key]\n",
    "        # Check if all elements are in the list\n",
    "        TF_bool = all(elem in df_temp_filtered['EVENT_CODE'].values for elem in value)\n",
    "        if TF_bool == True:\n",
    "            temp_count_order += 1\n",
    "    dictionary_counts[key] = temp_count_order\n",
    "\n",
    "\n",
    "    # Get counts of subgroup within each key\n",
    "    if key == \"Routine Biochemistry\":\n",
    "        Routine_Biochemistry_five_plus_66512 = int(0)\n",
    "        Routine_Biochemistry_four_66509 = int(0)\n",
    "        Routine_Biochemistry_three_66506 = int(0)\n",
    "        Routine_Biochemistry_two_66503 = int(0)\n",
    "        Routine_Biochemistry_one_66500 = int(0)      \n",
    "        for a_batch_key in unique_test_batches:\n",
    "            #create a temporary dataframe of all the results with just that combination of datetime,patientid,key Test results (eg Hormones test results)\n",
    "            df_temp_filtered = temp_tests_df[temp_tests_df['PATIENT_ID_AND_DT'] == a_batch_key]\n",
    "            # Get the count of the tests for the patient datetime key and hormones\n",
    "            count_tests_temp = df_temp_filtered.shape[0]\n",
    "            if count_tests_temp > 4:\n",
    "                Routine_Biochemistry_five_plus_66512 +=1\n",
    "            if count_tests_temp == 4:\n",
    "                Routine_Biochemistry_four_66509 +=1\n",
    "            if count_tests_temp == 3:\n",
    "                Routine_Biochemistry_three_66506 +=1\n",
    "            if count_tests_temp == 2:\n",
    "                Routine_Biochemistry_two_66503 +=1\n",
    "            if count_tests_temp == 1:\n",
    "                Routine_Biochemistry_one_66500 +=1\n",
    "        dictionary_counts[\"Routine_Biochemistry_five_plus_66512\"] = Routine_Biochemistry_five_plus_66512\n",
    "        dictionary_counts[\"Routine_Biochemistry_four_66509\"] = Routine_Biochemistry_four_66509\n",
    "        dictionary_counts[\"Routine_Biochemistry_three_66506\"] = Routine_Biochemistry_three_66506\n",
    "        dictionary_counts[\"Routine_Biochemistry_two_66503\"] = Routine_Biochemistry_two_66503\n",
    "        dictionary_counts[\"Routine_Biochemistry_one_66500\"] = Routine_Biochemistry_one_66500\n",
    "\n",
    "    if key == \"Hormones\":\n",
    "        hormones_five_plus_66707 = int(0)\n",
    "        hormones_four_66704 = int(0)\n",
    "        hormones_three_66701 = int(0)\n",
    "        hormones_two_66698 = int(0)\n",
    "        hormones_one_66695 = int(0)\n",
    "        for a_batch_key in unique_test_batches:\n",
    "            #create a temporary dataframe of all the results with just that combination of datetime,patientid,key Test results (eg Hormones test results)\n",
    "            df_temp_filtered = temp_tests_df[temp_tests_df['PATIENT_ID_AND_DT'] == a_batch_key]\n",
    "            # Get the count of the tests for the patient datetime key and hormones\n",
    "            count_tests_temp = df_temp_filtered.shape[0]\n",
    "            if count_tests_temp > 4:\n",
    "                hormones_five_plus_66707 +=1\n",
    "            if count_tests_temp == 4:\n",
    "                hormones_four_66704 +=1\n",
    "            if count_tests_temp == 3:\n",
    "                hormones_three_66701 +=1\n",
    "            if count_tests_temp == 2:\n",
    "                hormones_two_66698 +=1\n",
    "            if count_tests_temp == 1:\n",
    "                hormones_one_66695 +=1\n",
    "        dictionary_counts[\"hormones_five_plus_66707\"] = hormones_five_plus_66707\n",
    "        dictionary_counts[\"hormones_four_66704\"] = hormones_four_66704\n",
    "        dictionary_counts[\"hormones_three_66701\"] = hormones_three_66701\n",
    "        dictionary_counts[\"hormones_two_66698\"] = hormones_two_66698\n",
    "        dictionary_counts[\"hormones_one_66695\"] = hormones_one_66695\n",
    "\n",
    "    if key == \"Tumour Markers\":\n",
    "        Tumour_Markers_two_plus_66653 = int(0)\n",
    "        Tumour_Markers_one_66650 = int(0)\n",
    "        for a_batch_key in unique_test_batches:\n",
    "            #create a temporary dataframe of all the results with just that combination of datetime,patientid,key Test results (eg Hormones test results)\n",
    "            df_temp_filtered = temp_tests_df[temp_tests_df['PATIENT_ID_AND_DT'] == a_batch_key]\n",
    "            # Get the count of the tests for the patient datetime key and hormones\n",
    "            count_tests_temp = df_temp_filtered.shape[0]\n",
    "            if count_tests_temp > 1:\n",
    "                Tumour_Markers_two_plus_66653 +=1\n",
    "            if count_tests_temp == 1:\n",
    "                Tumour_Markers_one_66650 +=1\n",
    "        dictionary_counts[\"Tumour_Markers_two_plus_66653\"] = Tumour_Markers_two_plus_66653\n",
    "        dictionary_counts[\"Tumour_Markers_one_66650\"] = Tumour_Markers_one_66650\n",
    "\n",
    "    if key == \"Coagulation\":\n",
    "        Coagulation_three_plus_65126 = int(0)\n",
    "        Coagulation_two_65123 = int(0)\n",
    "        Coagulation_one_65120 = int(0)\n",
    "        for a_batch_key in unique_test_batches:\n",
    "            #create a temporary dataframe of all the results with just that combination of datetime,patientid,key Test results (eg Hormones test results)\n",
    "            df_temp_filtered = temp_tests_df[temp_tests_df['PATIENT_ID_AND_DT'] == a_batch_key]\n",
    "            # Get the count of the tests for the patient datetime key and hormones\n",
    "            count_tests_temp = df_temp_filtered.shape[0]\n",
    "            if count_tests_temp > 2:\n",
    "                Coagulation_three_plus_65126 +=1\n",
    "            if count_tests_temp == 2:\n",
    "                Coagulation_two_65123 +=1\n",
    "            if count_tests_temp == 1:\n",
    "                Coagulation_one_65120 +=1\n",
    "        dictionary_counts[\"Coagulation_three_plus_65126\"] = Coagulation_three_plus_65126\n",
    "        dictionary_counts[\"Coagulation_two_65123\"] = Coagulation_two_65123\n",
    "        dictionary_counts[\"Coagulation_one_65120\"] = Coagulation_one_65120\n",
    "\n",
    "for key, value in dictionary_counts.items():\n",
    "    print(key, value)\n",
    "\n",
    "# Export the dictionary to Excel\n",
    "df = pd.DataFrame.from_dict(dictionary_counts,orient='index')\n",
    "df.to_excel(output_location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99ab24223154bc81de56fc605a85b0e4b0e8fba2ce28055bc07242989cabcf2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Implant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes created:\n",
      "- df_CERNER (original sheet name: 'CERNER')\n",
      "- df_Prescribed_List (original sheet name: 'Prescribed List')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import re\n",
    "\n",
    "# Load the Excel file\n",
    "excel_file = 'Implant-Data.xlsx'\n",
    "\n",
    "# Get all sheet names\n",
    "workbook = openpyxl.load_workbook(excel_file)\n",
    "sheet_names = workbook.sheetnames\n",
    "\n",
    "# Create a dictionary to store dataframes\n",
    "dataframes = {}\n",
    "\n",
    "def clean_sheet_name(name):\n",
    "    # Replace spaces and special characters with underscores\n",
    "    # Remove any characters that aren't alphanumeric or underscore\n",
    "    cleaned_name = re.sub(r'\\W+', '_', name)\n",
    "    # Ensure the name starts with a letter or underscore\n",
    "    if not cleaned_name[0].isalpha() and cleaned_name[0] != '_':\n",
    "        cleaned_name = '_' + cleaned_name\n",
    "    return cleaned_name\n",
    "\n",
    "# Load each sheet into a separate dataframe\n",
    "for sheet in sheet_names:\n",
    "    # Read the sheet, converting all columns to string (object) dtype\n",
    "    df = pd.read_excel(excel_file, sheet_name=sheet, dtype=str)\n",
    "    \n",
    "    # Create a valid variable name for the dataframe\n",
    "    df_name = f\"df_{clean_sheet_name(sheet)}\"\n",
    "    \n",
    "    # Store the dataframe in the dictionary\n",
    "    dataframes[df_name] = df\n",
    "    \n",
    "    # Create a global variable with the dataframe name\n",
    "    globals()[df_name] = df\n",
    "\n",
    "print(\"Dataframes created:\")\n",
    "for df_name, original_sheet in zip(dataframes.keys(), sheet_names):\n",
    "    print(f\"- {df_name} (original sheet name: '{original_sheet}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new codes: 878\n",
      "Number of unfound codes: 2419\n",
      "\n",
      "First 5 new codes:\n",
      "['AK013', 'AL059', 'AL060', 'AO049', 'AO050']\n",
      "\n",
      "First 5 unfound codes:\n",
      "['AA009', 'AAA02', 'AAA05', 'AAA06', 'AAA08']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_CERNER and df_Prescribed_List are already loaded\n",
    "\n",
    "# Convert the relevant columns to sets for efficient comparison\n",
    "cerner_codes = set(df_CERNER['SOURCE_IDENTIFIER'])\n",
    "prescribed_codes = set(df_Prescribed_List['Billing Code'])\n",
    "\n",
    "# Find new codes (in Prescribed List but not in CERNER)\n",
    "new_codes = list(prescribed_codes - cerner_codes)\n",
    "\n",
    "# Find unfound codes (in CERNER but not in Prescribed List)\n",
    "unfound_codes = list(cerner_codes - prescribed_codes)\n",
    "\n",
    "# Sort the lists for easier reading\n",
    "new_codes.sort()\n",
    "unfound_codes.sort()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of new codes: {len(new_codes)}\")\n",
    "print(f\"Number of unfound codes: {len(unfound_codes)}\")\n",
    "\n",
    "# Optional: Print the first few items of each list\n",
    "print(\"\\nFirst 5 new codes:\")\n",
    "print(new_codes[:5])\n",
    "print(\"\\nFirst 5 unfound codes:\")\n",
    "print(unfound_codes[:5])\n",
    "\n",
    "# Optional: Save the lists to CSV files\n",
    "pd.Series(new_codes).to_csv('new_codes.csv', index=False, header=['New Codes'])\n",
    "pd.Series(unfound_codes).to_csv('unfound_codes.csv', index=False, header=['Unfound Codes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of distinct codes in Oracle (Cerner) SOURCE_IDENTIFIER is: 11214\n",
      "The number of distinct codes in The Government Data 'Billing Code' is: 9673\n",
      "New Codes to be added:\n",
      "878\n",
      "Unfound Codes to be deactivated:\n",
      "2419\n"
     ]
    }
   ],
   "source": [
    "# Count distinct codes\n",
    "distinct_cerner_count = df_CERNER['SOURCE_IDENTIFIER'].nunique()\n",
    "distinct_gov_count = df_Prescribed_List['Billing Code'].nunique()\n",
    "# Print the result\n",
    "print(f\"The number of distinct codes in Oracle (Cerner) SOURCE_IDENTIFIER is: {distinct_cerner_count}\")\n",
    "print(f\"The number of distinct codes in The Government Data 'Billing Code' is: {distinct_gov_count}\")\n",
    "\n",
    "print(\"New Codes to be added:\")\n",
    "print(len(new_codes))\n",
    "print(\"Unfound Codes to be deactivated:\")\n",
    "print(len(unfound_codes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
